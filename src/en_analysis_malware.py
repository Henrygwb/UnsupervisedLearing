import os
import pandas as pd
import numpy as np
from scipy import io
from keras.models import load_model
from keras.utils import to_categorical
from keras import backend as K
from util import ensemble, metrics, DimReduce, Cluster
from MeanUncertaintyCluster import ParititionAlignment, ClusterAnalysis, ota_c, confset_c, par_stability_c
from collections import Counter
metrics = metrics()

def load_clustering(path, cls, num_bs):
    y = io.loadmat(os.path.join(path, 'label'))['y'].flatten()
    yb = np.zeros((len(cls)*num_bs, y.shape[0]))
    for i in xrange(len(cls)):
        folder_1 = 'cluster_'+str(cls[i])
        path_1 = os.path.join(path, folder_1)
        for j in xrange(num_bs):
            folder = str(j)+'_bs'
            path_2 = os.path.join(path_1, folder)
            tmp = io.loadmat(os.path.join(path_2, 'low_2'))['y_pred'].flatten()
            print np.unique(tmp)
            yb[i*num_bs+j,] = tmp
            acc = np.round(metrics.acc(y, tmp), 5)
            nmi = np.round(metrics.nmi(y, tmp), 5)
            ari = np.round(metrics.ari(y, tmp), 5)
            print '****************************************'
            print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    return y, np.array(yb)

def normalize(x):
    x = (x - np.min(x, axis=0)) / (np.max(x, axis=0) - np.min(x, axis=0))
    return x


def load_x(data_path_1, data_path_2, use_two = 0):
    recover_files = np.load(data_path_1)
    dex = recover_files['x_train_dex']
    x_opcode_count = dex[:,0:11+256+1]
    x_dex_op = normalize(x_opcode_count)
    x_dex_permission = dex[:,11+256+1:]
    x_sandbox = recover_files['x_train__sandbox'].astype('float32')
    y_fal_1 = recover_files['y_train_family']

    if use_two == 1:
        recover_files_2 = np.load(data_path_2)
        dex_2 = recover_files_2['x_train_dex']
        x_opcode_count = dex_2[:,0:11+256+1]
        x_dex_op = np.vstack((x_dex_op,normalize(x_opcode_count)))
        x_dex_permission = np.vstack((x_dex_permission, dex_2[:,11+256+1:]))
        x_sandbox = np.vstack((x_sandbox, recover_files_2['x_train__sandbox'].astype('float32')))
        y_fal_1 = np.concatenate((y_fal_1, recover_files_2['y_train_family']))

    nonzero_row = np.where(y_fal_1==0)[0]
    x_dex_op = np.delete(x_dex_op, nonzero_row, 0)
    x_dex_permission = np.delete(x_dex_permission, nonzero_row, 0)
    x_sandbox = np.delete(x_sandbox, nonzero_row, 0)
    y_fal_1 = np.delete(y_fal_1, nonzero_row, 0) - 1

    x_dex_permission = np.expand_dims(x_dex_permission, axis=-1)
    y_fal = to_categorical(y_fal_1)
    x_sandbox_1 = np.expand_dims(x_sandbox, axis=-1)

    print y_fal_1.shape
    print np.where(y_fal_1==0)[0].shape[0]
    print np.where(y_fal_1==1)[0].shape[0]
    print np.where(y_fal_1==2)[0].shape[0]
    print np.where(y_fal_1==3)[0].shape[0]
    print np.where(y_fal_1==4)[0].shape[0]

    return x_dex_op, x_dex_permission, x_sandbox

def cluster_selection(y,
                      yb,
                      n_bootstrap,
                      using_c =0,
                      compare = 0):

    ########### Mean partition #######################
    num_sample = y.shape[0]
    # yb = np.hstack((y_orin, yb))
    if n_bootstrap != yb.shape[0]/num_sample:
        n_bootstrap = yb.shape[0]/num_sample
        print 'Changing the bootstrap number to ' + str(n_bootstrap)

    mean_cluster = ParititionAlignment(y, yb, n_bootstrap)
    if using_c == 1:
        y_mean, dist = ota_c(yb, num_sample, n_bootstrap, return_mean = 1)
        y_best, dist = ota_c(yb, num_sample, n_bootstrap, return_mean = 0)

        print '************ Partition stability *****************'
        p_s = par_stability_c(yb, n_bootstrap, num_sample)
        print p_s

    else:
        y_mean, dist = mean_cluster.ota()
        idx, dist = mean_cluster.ref_idx(yb)
        y_best = yb[(idx-1)*num_sample:idx*num_sample]

        en = ensemble(yb, n_bootstrap, num_sample)
        if compare == 1:
            y_vote = en.voting()
            print 'Clustering result of voting.'
            acc = np.round(metrics.acc(y, y_vote), 5)
            nmi = np.round(metrics.nmi(y, y_vote), 5)
            ari = np.round(metrics.ari(y, y_vote), 5)
            print '****************************************'
            print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))
            y_cspa = en.CSPA()
            print 'Clustering result of CSPA.'
            acc = np.round(metrics.acc(y, y_cspa), 5)
            nmi = np.round(metrics.nmi(y, y_cspa), 5)
            ari = np.round(metrics.ari(y, y_cspa), 5)
            print '****************************************'
            print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))
            y_mcla = en.MCLA()
            print 'Clustering result of MCLA.'
            acc = np.round(metrics.acc(y, y_mcla), 5)
            nmi = np.round(metrics.nmi(y, y_mcla), 5)
            ari = np.round(metrics.ari(y, y_mcla), 5)
            print '****************************************'
            print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

            ########### Partition stability #######################
            print '************ Partition stability *****************'
            p_s = mean_cluster.par_stability(dist, metric='mean')
            print p_s
    return y_mean, y_best


def cluster_analysis(y, yb, y_mean, n_bootstrap, using_c , threshold = 0.8, alpha = 0.1):
    num_sample = y.shape[0]
    # yb = np.hstack((y_orin, yb))
    if n_bootstrap != yb.shape[0] / num_sample:
        n_bootstrap = yb.shape[0] / num_sample
        print 'Changing the bootstrap number to ' + str(n_bootstrap)

    ########### Confident point set #######################
    if using_c == 1:
        confidentset, \
        Interset, \
        cluster_id, \
        dist, \
        cluster_analy = confset_c(yb, num_sample, n_bootstrap, threshold, alpha)
    else:
        mean_cluster = ParititionAlignment(y, yb, n_bootstrap)
        cluster_analy = ClusterAnalysis(yb, n_bootstrap, y_mean, len = num_sample)
        wt, clst, dist = mean_cluster.align(yb, y_mean)
        codect, nfave, res = cluster_analy.matchsplit(wt=wt, clsct=clst)
        cluster_id, sample_id = cluster_analy.matchcluster(res, clst)
        confidentset, S = cluster_analy.confset(sample_id, cluster_id)
        Interset = cluster_analy.interset(sample_id, cluster_id)

    print 'Relabeling....'
    new_cluster_id = np.zeros_like(cluster_id)
    new_confidentset = {}
    new_interset = {}
    new_y_mean = np.zeros_like(y_mean)
    for i in xrange(len(confidentset)):
        idx = confidentset[i]
        y_cls = y[idx]
        b = Counter(y_cls).most_common(1)
        print b
        new_confidentset[b[0][0]] = confidentset[i]
        new_cluster_id[b[0][0]] = cluster_id[i]
        new_interset[b[0][0]] = Interset[i]
        new_y_mean[y_mean==i] = b[0][0]

    # if option == 'dcn' and path == '../results/mnist':
    #     new_confidentset[9] = confidentset[1]
    #     new_cluster_id[9] = cluster_id[1]
    #     new_interset[9] = Interset[1].astype('int')
    #     new_y_mean[y_mean == 1] = 9
    #     new_y_mean = new_y_mean.astype('int')

    print '************************************'
    for i in xrange(len(new_confidentset)):
        idx = new_confidentset[i]
        y_cls = y[idx]
        b = Counter(y_cls).most_common(1)
        print b
        print idx.shape[0]
        print b[0][1] / float(idx.shape[0])

    ########### Cluster stability #######################
    print '************ Cluster stability *****************'
    stability = np.zeros((len(new_confidentset), 2))
    yb = yb.reshape(n_bootstrap, num_sample)
    yb = np.vstack((y_mean.reshape(1, num_sample), yb))
    for i in xrange(len(new_confidentset)):
        confset = new_confidentset[i]
        S_idx = new_cluster_id[i, ].astype('int')
        SS = []
        for ii in xrange(S_idx.shape[0]):
            if S_idx[ii] != -1:
                SS.append(np.where(yb[ii]==S_idx[ii])[0])
        atr, acr = cluster_analy.clu_stability(confset, SS)
        stability[i, 0] = atr
        stability[i, 1] = acr
    print np.round(stability, 4)[:,0]
    print np.round(stability, 4)[:,1]


    ########### Cluster distance #######################
    print '************ Cluster distance *****************'
    cls_dis = np.zeros((len(new_confidentset), len(new_confidentset)))
    for i in xrange(len(new_confidentset)):
        for j in xrange(len(new_confidentset)):
            cls_dis[i,j] = cluster_analy.clu_dist(new_confidentset, i, j)
    print np.around(cls_dis, decimals=3)

    return new_y_mean, new_confidentset, new_interset

# def draw_figure(X, y, y_mean, confidentset, Interset, option):
#     from ggplot import *
#     feat_cols = ['tsne-x', 'tsne-y']
#     df = pd.DataFrame(X, columns=feat_cols)
#     df['label'] = [str(i) for i in y]
#     p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
#         geom_point() + \
#         scale_color_brewer(type='diverging', palette=4)+ \
#         xlab(" ") + ylab(" ") + \
#         ggtitle("Ground Truth")
#     p.save(option + '_Original_Clusters.png')
#     #plt.clf()
#
#     df['label'] = [str(i) for i in y_mean]
#     p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
#         geom_point() + \
#         scale_color_brewer(type='diverging', palette=4) + \
#         ggtitle("Mean")+ xlab(" ") + ylab(" ")
#     #   +theme(axis_text_x=ggplot.theme_blank(), axis_text_y=ggplot.theme_blank())
#     p.save(option+'_Mean_Clusters.png')
#
#     for i in xrange(len(confidentset)):
#         y_conf = np.zeros_like(y)
#         idx = confidentset[i]
#         y_conf[idx] = 1
#         df['label'] = [str(ii) for ii in y_conf]
#         p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
#             geom_point() + scale_color_brewer(type='diverging', palette=4) \
#             + ggtitle('Confset_'+str(i))+ xlab(" ") + ylab(" ")
#         p.save(option+'_confset_'+str(i)+'.png')
#
#
#     for i in xrange(len(Interset)):
#         y_conf = np.zeros_like(y)
#         idx = Interset[i]
#         y_conf[idx] = 1
#         df['label'] = [str(ii) for ii in y_conf]
#         p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
#             geom_point() + \
#             scale_color_brewer(type='diverging', palette=4) + \
#             ggtitle('Interset_' + str(i))+ xlab(" ") + ylab(" ")
#         p.save(option + '_interset_' + str(i) + '.png')


def show_low_d(X, y, y_3, y_4, y_5, y_6):

    from ggplot import *
    feat_cols = ['tsne-x', 'tsne-y']
    df = pd.DataFrame(X, columns=feat_cols)
    df['label'] = [str(i) for i in y]
    p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
        geom_point() + \
        scale_color_brewer(type='diverging', palette=4)+ \
        xlab(" ") + ylab(" ") + \
        ggtitle("Ground Truth")
    p.save('Original_Clusters.png')
    #plt.clf()

    df['label'] = [str(i) for i in y_3]
    p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
        geom_point() + \
        scale_color_brewer(type='diverging', palette=4) + \
        ggtitle("Three Clusters")+ xlab(" ") + ylab(" ")
    #   +theme(axis_text_x=ggplot.theme_blank(), axis_text_y=ggplot.theme_blank())
    p.save('Three Clusters.png')

    df['label'] = [str(i) for i in y_4]
    p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
        geom_point() + \
        scale_color_brewer(type='diverging', palette=4) + \
        ggtitle("Four Clusters")+ xlab(" ") + ylab(" ")
    #   +theme(axis_text_x=ggplot.theme_blank(), axis_text_y=ggplot.theme_blank())
    p.save('Four Clusters.png')

    df['label'] = [str(i) for i in y_5]
    p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
        geom_point() + \
        scale_color_brewer(type='diverging', palette=4) + \
        ggtitle("Five Clusters")+ xlab(" ") + ylab(" ")
    #   +theme(axis_text_x=ggplot.theme_blank(), axis_text_y=ggplot.theme_blank())
    p.save('Five Clusters.png')

    df['label'] = [str(i) for i in y_6]
    p = ggplot(df, aes(x='tsne-x', y='tsne-y', color='label')) + \
        geom_point() + \
        scale_color_brewer(type='diverging', palette=4) + \
        ggtitle("Six Clusters")+ xlab(" ") + ylab(" ")
    #   +theme(axis_text_x=ggplot.theme_blank(), axis_text_y=ggplot.theme_blank())
    p.save('Six Clusters.png')


if __name__ == "__main__":
    """
    path = '../results/malware'
    cls = [3,4,5,6]
    num_bs = 5
    y, yb = load_clustering(path, cls, num_bs)

    y_mean, y_best = cluster_selection(y, yb.flatten(), n_bootstrap=num_bs*len(cls), using_c=1)
    acc = np.round(metrics.acc(y, y_mean), 5)
    nmi = np.round(metrics.nmi(y, y_mean), 5)
    ari = np.round(metrics.ari(y, y_mean), 5)
    print '****************************************'
    print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    acc = np.round(metrics.acc(y, y_best), 5)
    nmi = np.round(metrics.nmi(y, y_best), 5)
    ari = np.round(metrics.ari(y, y_best), 5)
    print '****************************************'
    print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    x_low = io.loadmat('../results/malware/low_d_5')['x_low']
    yb3 = yb[4,].astype('int')
    print np.unique(yb3)
    acc = np.round(metrics.acc(y, yb3), 5)
    nmi = np.round(metrics.nmi(y, yb3), 5)
    ari = np.round(metrics.ari(y, yb3), 5)
    print '****************************************'
    print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    yb4 = yb[9,].astype('int')
    print np.unique(yb4)
    acc = np.round(metrics.acc(y, yb4), 5)
    nmi = np.round(metrics.nmi(y, yb4), 5)
    ari = np.round(metrics.ari(y, yb4), 5)
    print '****************************************'
    print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    yb5 = yb[14,].astype('int')
    print np.unique(yb5)
    acc = np.round(metrics.acc(y, yb5), 5)
    nmi = np.round(metrics.nmi(y, yb5), 5)
    ari = np.round(metrics.ari(y, yb5), 5)
    print '****************************************'
    print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    yb6 = yb[19,].astype('int')
    print np.unique(yb6)
    acc = np.round(metrics.acc(y, yb6), 5)
    nmi = np.round(metrics.nmi(y, yb6), 5)
    ari = np.round(metrics.ari(y, yb6), 5)
    print '****************************************'
    print('acc = %.5f, nmi = %.5f, ari = %.5f.' % (acc, nmi, ari))

    show_low_d(x_low, y, yb3, yb4, yb5, yb6)
    """
    
